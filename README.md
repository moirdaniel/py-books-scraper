# üìò Web Scraping de Libros ‚Äî Books to Scrape

Proyecto completo de Web Scraping que obtiene informaci√≥n desde **https://books.toscrape.com** y la almacena en una base de datos local SQLite.
Incluye scraping del listado, scraping del detalle, normalizaci√≥n de datos, manejo de errores, logs, control de duplicados y exportaci√≥n a CSV.

## üöÄ Objetivo del Proyecto

Construir un scraper robusto capaz de:

1. Navegar por las primeras **3 p√°ginas del cat√°logo**.
2. Extraer informaci√≥n relevante de cada libro.
3. Ingresar a la p√°gina de detalle para obtener informaci√≥n adicional.
4. Guardar los datos en una base SQLite con esquema definido.
5. Registrar errores y eventos mediante logging.
6. Evitar duplicados usando el **UPC** como clave natural.

Este proyecto es ideal para pr√°cticas profesionales en:

- Web Scraping
- Limpieza y transformaci√≥n de datos
- Persistencia en SQLite
- Automatizaci√≥n de pipelines
- Buenas pr√°cticas de requests (user-agent, delay, timeouts)

---

## üß∞ Tecnolog√≠as Utilizadas

### Lenguaje
- Python 3.10+

### Librer√≠as de scraping
- `requests`
- `beautifulsoup4`
- `lxml`

### Persistencia
- `sqlite3`

### Utilidades
- `logging`
- `csv`
- `re`
- `time`

---

## üìÅ Estructura del Proyecto

```
books-scraper/
‚îú‚îÄ scrape_books.py
‚îú‚îÄ export_first_10.py
‚îú‚îÄ requirements.txt
‚îî‚îÄ README.md
```

---

## üîç Funcionalidades del Proyecto

### 1. Scraping del Cat√°logo
Extrae:
- T√≠tulo  
- Precio  
- Disponibilidad  
- Rating  
- URL de imagen  
- URL de detalle  

### 2. Scraping del Detalle
Extrae:
- Descripci√≥n  
- UPC  
- Categor√≠a  

### 3. Manejo de Errores
Incluye:
- Timeouts  
- Excepciones HTTP  
- Validaci√≥n de elementos faltantes  
- Logging  

### 4. Control de Duplicados
El campo **UPC** se usa como clave natural para evitar inserciones repetidas.

### 5. Buenas Pr√°cticas de Scraping
Delay de **1 segundo** entre requests, user-agent personalizado y parseo eficiente con `lxml`.

---

## üóÑÔ∏è Base de Datos SQLite

La base se crea autom√°ticamente al ejecutar el scraper.

### Esquema

```sql
CREATE TABLE libros (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  titulo TEXT NOT NULL,
  precio DECIMAL(10,2),
  disponibilidad TEXT,
  rating INTEGER,
  url_imagen TEXT,
  descripcion TEXT,
  upc TEXT,
  categoria TEXT,
  fecha_extraccion TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

## ‚ñ∂Ô∏è C√≥mo Ejecutar el Proyecto

### 1. Crear entorno virtual (opcional)

Windows:
```
python -m venv venv
venv\Scripts\activate
```

Linux/Mac:
```
python3 -m venv venv
source venv/bin/activate
```

### 2. Instalar dependencias
```
pip install -r requirements.txt
```

### 3. Ejecutar el scraper
```
python scrape_books.py
```

### 4. Exportar los primeros 10 registros
```
python export_first_10.py
```

---

## üñ•Ô∏è Ver la Base de Datos

CLI SQLite:
```
sqlite3 libros.db
.tables
SELECT * FROM libros LIMIT 10;
.exit
```

GUI recomendadas:
- DB Browser for SQLite
- SQLiteStudio

---

## ‚úîÔ∏è Estado del Proyecto

Incluye:
- Scraper funcional  
- Logs  
- Base SQLite  
- Export CSV  
- Manejo de errores  
- Control de duplicados  
- Documentaci√≥n detallada  

---

## üìå Notas Finales

BooksToScrape est√° dise√±ado para practicar scraping y no posee restricciones fuertes, lo que lo hace ideal para entrenamiento y pruebas controladas.
